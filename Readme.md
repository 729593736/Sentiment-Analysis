Reference为整个Project中的参考信息来源，

该Project数据集
1.来自豆瓣的影评，28 部电影，超 70 万 用户，超 200 万条 评分/评论 数据，
打分为1-5分，该project取1为差评，label 0
		        3为中评，label 1
		        5为好评，label 2
我筛选了其中好中差评各10000条，其中取27000条为训练集，3000条为测试集

2.来自某公司的推特评论
共1500+1500训练集，好评/差评，测试集约1500条，约100差评


整体思路，通过Bert model的调用对文本实现情感分类任务，
1.文件分割，见data中筛选.py，将超大.csv文件通过rating也就是星级分割，获取目标数据集
2.文件读入，如上所述三个星级对应三个label
3.Tokenize，也就是预处理类似于token embedding，用tokenize.encode/plus方法
4.预处理Bert模型调用
5.网络搭建，Bert调用+全连接+relu+全连接（768（bert固定输出维度）100（全连接层，随便多少层，适当就好）n（n分类））
6.优化器以及精度，调用自适应函数，以及lookback等训练操作也是调用函数。
7.训练搭建，因为训练时间较长，所以我们选择批量，并且批量打印，batch size 我这里用的32（大型的一般用512）
8.评估，也就是测试集loss以及accuracy计算，通过argmax函数获取概率最大下标，即logits的max，对应序号即为label，故可直接if ==判断。
9.开始训练and测试，采用同步，当然可以将evalution参数设置为flase，就可以单纯训练，不进行测评，设置epoch即可选择训练次数。
10.整体细节较多，主要为各种数据类型的转换以及GPU与CPU的交互，因为大型网络，所以CPU速度过慢，batch size 32跑20个size就要300s，换GPU只需10s
注：如果测试集没有label，可采用分割训练集得到验证集的方式去调节网络参数，下列[1]就是采用这种方式。

2021.11.4-11.8
运行记录：
训练集每类9k数据集，训练集一般为每类1k；
1.利用英文数据集进行二分类，因为数据可能过于中和，运行正确率在85%左右，其中测试集没有label输出自己评价可以发现测试集正确率和验证集类似，大约85%，epoch为2
2.利用上述影评二分类，label 0 1 对应1 5星影评，正确率在99%+
3.利用上述影评三分类，label 0 1 2对应1 3 5星影评，正确率在99%左右
4.利用上述影评四分类，label 0 1 2 3对应1 3 4 5星影评，小数据训练，135星各9k训练集，4星10个训练集，输出相同大小，准确率78%左右，也就是说基本预测错误，说明不可以进行小规模训练。
5.利用上述影评五分类，label 0 1 2 3 4对应1 2 3 4 5星影评，正确率97%+
6.利用上述影评五分类，label 0 1 2 3 4对应1 2 3 4 5星影评，但是测试集用另外的电影影评，正确率为很低，会发现大部分评价都偏移为另一同类，应该是因为电影不通的缘故，
导致某些学习的信息在评判标准上会有统一误差，普遍是评级下降，比如真实5星4星都转化为3星，而三星及以下直接归类为1星，这应该是学习方式的原因，但是除了应该正确归类的，
剩下都都是偏移一类，所以另一方面来说又比较准确，因为至少分类一致，不过这也说明二分类的话就是完全没有问题了，可以应用于其他语境sentiment analysis

总结：以此类推，只要是语境相同，多分类问题的准确率是十分可观的，但是只要语境不通就容易整体向下偏移。而且都是一个epoch的结果，因为准确率已经十分可观了，
之前训练过多epoch，英文文本二分类问题，就是[1],增加的正确率并没有非常高，因为其实我们的网络主要起的是微调作用，因为调用了预训练bert模型。

2021.11.9
运行记录更新：
发现通过更改各类训练样本的个数，将偏移改正
例如对应改为1w，1k，1k，1k，1k，1星正确率达到99%+，但是因为还要考虑其他类别文本，
现尝试将训练集改为两端峰值如下：
8k 1k 2k 1k 8k正确率：
一星：97%
二星：99.8%
三星：8%，基本上归类到二星去了，
四星：16%，同上
五星：7%，同上
所以说基本上不适合不同语境

经过多次更改，发现效果不大，但是产生了新的想法，
如果把意义相同的更改label距离效果会不会很好，试了之后发现没有任何用处
因为一开始觉得可能是label的数值有所影响，但是后来发现是用的差求loss，没有关系。

又试了下500 100 500 100 1k
三星:97%
但是一星正确率又下去了

这就说明其实我们如果进行多分类，测试集用的其他语境的时候，可以通过调整训练集的
数量分布来使其中的某几个分类达到期望水准，但是也可能是训练集的文本不适合新的
情感分类的标准，毕竟主题不一样，所以那种通用的感觉要训练基础的常用语句。



如有问题联系作者
注：此为自然语言处理大作业
2021.11.8